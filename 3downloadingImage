from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
import pandas as pd
from tabulate import tabulate
import time
import requests
import os

# Google Sheets CSV URL
sheet_id = '1MQGvVQMZcRreOW_3d8UaCmmEni6ttE618cII2yTsJz0'
df = pd.read_csv(f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv")

print(df)
print(tabulate(df, headers='keys', tablefmt='psql'))

# Updated path to the ChromeDriver executable
chrome_driver_path = r"C:\Users\RGB PC GAMER\Desktop\pythhon scrapper\Chrome web driver\chromedriver-win64\chromedriver.exe"

# Updated path to the custom Chrome executable
chrome_exe_path = r"C:\Users\RGB PC GAMER\Desktop\pythhon scrapper\Chrome\chrome-win64\chrome.exe"

# Set Chrome options to point to the custom Chrome executable
chrome_options = Options()
chrome_options.binary_location = chrome_exe_path

# Create a Service object for ChromeDriver
service = Service(executable_path=chrome_driver_path)

# Manually set the row index to test
row_index = 2  # Change this index manually to test different rows

try:
    # Initialize the WebDriver with the Service object and Chrome options
    driver = webdriver.Chrome(service=service, options=chrome_options)

    # Open Google
    driver.get('https://google.com')

    # Process the specific row based on row_index
    if row_index < len(df):
        row = df.iloc[row_index]
        name = row['NAME']
        location_zip = row['LOCATION_ZIP']
        location_street = row['LOCATION_STREET']
        establishment_id = row['ESTABLISHMENT_ID']

        # Construct search query
        search_query = f"{name} {location_street} {location_zip}"

        # Print search query
        print(f"\nProcessing Entry {row_index + 1}/{len(df)}")
        print(f"Search Query: {search_query}")

        # Locate the search box and perform the search
        search_box = driver.find_element("name", "q")
        search_box.clear()  # Clear the previous query
        search_box.send_keys(search_query)
        search_box.send_keys(Keys.RETURN)

        # Print the current URL after search
        search_url = driver.current_url
        print(f"Search URL: {search_url}")

        # Wait for results to load
        time.sleep(5)

        # Print search results page title
        print(driver.title)

        # Find Instagram links in the search results
        search_results = driver.find_elements("css selector", "a")
        found = False
        for result in search_results:
            href = result.get_attribute("href")
            if href and "instagram.com" in href:
                print(f"Found Instagram link: {href}")
                result.click()
                found = True
                break  # Click the first Instagram link found

        if not found:
            print("No Instagram link found.")
            df.at[row_index, 'Status'] = 'Not Found'
        else:
            # Wait for Instagram profile page to load
            time.sleep(5)

            # Use JavaScript to get the profile picture
            profile_picture_url = driver.execute_script(
                "return document.querySelector('img[alt*=\"profile picture\"]').src;"
            )

            if profile_picture_url:
                # Download the profile picture
                response = requests.get(profile_picture_url)
                with open(f"collectedImages/{establishment_id}.jpg", "wb") as file:
                    file.write(response.content)

                # Update the Status column in the spreadsheet
                df.at[row_index, 'Status'] = 'Done'
            else:
                print("Profile picture not found.")
                df.at[row_index, 'Status'] = 'Not Found'

    else:
        print("Row index out of range.")

    # Wait indefinitely to keep the browser open
    input("Press Enter to keep the browser open and exit...")

finally:
    # Close the browser
    driver.quit()